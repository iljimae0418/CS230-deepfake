{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Here we are trying to convert videos into wav file from a folder and then trying to find out if there are any audio fakes . We then create spectrogram and compare the difference in np array between fake audio and its originals."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport subprocess\nimport glob\nimport os\nfrom pathlib import Path\nimport shutil\nfrom zipfile import ZipFile\nfrom scipy import signal\nfrom scipy.io import wavfile\nfrom skopt import gp_minimize\nfrom skopt.space import Real\nfrom functools import partial\nimport librosa.display\nimport librosa.filters\nimport matplotlib.pyplot as plt\nimport skimage","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using the Static Build of ffmpeg from https://johnvansickle.com/ffmpeg/ because internet is not available. <br>\nThe public data set can be found here:\nhttps://www.kaggle.com/rakibilly/ffmpeg-static-build\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"! tar xvf ../input/ffmpeg-static-build/ffmpeg-git-amd64-static.tar.xz","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Specify output format and create a directory for the output Audio files\nFor 400 mp3 files, the directory is approx 94 MB.<br>\nFor 400 wav files, the directory is approx 673 MB."},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_FOLDER = '../input/deepfake-detection-challenge/'\nTRAIN_SAMPLE_FOLDER = 'train_sample_videos/'\nTEST_FOLDER = 'test_videos/'\nDATA_PATH = os.path.join(DATA_FOLDER,TRAIN_SAMPLE_FOLDER)\nos.makedirs('/kaggle/working/output', exist_ok=True)\nos.makedirs('/kaggle/working/test_output', exist_ok=True)\nOUTPUT_PATH = '/kaggle/working/output'\nTEST_OUTPUT_PATH = '/kaggle/working/test_output/'\nprint(f\"Train samples: {len(os.listdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)))}\")\nprint(f\"Test samples: {len(os.listdir(os.path.join(DATA_FOLDER, TEST_FOLDER)))}\")\nSPLIT='00'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_list = list(os.listdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)))\next_dict = []\nfor file in train_list:\n    file_ext = file.split('.')[1]\n    if (file_ext not in ext_dict):\n        ext_dict.append(file_ext)\nprint(f\"Extensions: {ext_dict}\")      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"json_file = [file for file in train_list if  file.endswith('json')][0]\nprint(f\"JSON file: {json_file}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_meta_from_json(path):\n    df = pd.read_json(os.path.join(DATA_FOLDER, path, json_file))\n    df = df.T\n    return df\n\nmeta_train_df = get_meta_from_json(TRAIN_SAMPLE_FOLDER)\nmeta_train_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_format = 'wav'  # can also use aac, wav, etc\n\noutput_dir = Path(f\"{output_format}s\")\nPath(output_dir).mkdir(exist_ok=True, parents=True)\nfake_name ='aaeflzzhvy'\nreal_name = 'flqgmnetsg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta = (list(meta_train_df.index))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get the list of videos to extract audio from"},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_PATH = '../input/realfake045/assorted/'\nWAV_PATH = './wavs/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_files = []\nfor file in os.listdir(os.path.join(DATA_FOLDER,TRAIN_SAMPLE_FOLDER)):\n    filename = os.path.join(DATA_FOLDER,TRAIN_SAMPLE_FOLDER)+file\n    list_of_files.append(filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_files","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Extract the audio from files"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_wav(list_of_files):\n    for file in list_of_files:\n        command = f\"../working/ffmpeg-git-20191209-amd64-static/ffmpeg -i {file} -ab 192000 -ac 2 -ar 44100 -vn {output_dir/file[-14:-4]}.{output_format}\"\n        subprocess.call(command, shell=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ncreate_wav(list_of_files)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def create_spectogram(name,sr):\n    audio_array, sample_rate = librosa.load(WAV_PATH+f'{name}', sr=sr)\n    trim_audio_array, index = librosa.effects.trim(audio_array)\n    S = librosa.feature.melspectrogram(y=trim_audio_array, sr=sr, n_mels=128, fmax=8000)\n    S_dB = np.log(S + 1e-9)\n    # min-max scale to fit inside 8-bit range\n    img = scale_minmax(S_dB, 0, 255).astype(np.uint8)\n    img = np.flip(img, axis=0) # put low frequencies at the bottom in image\n    img = 255-img # invert. make black==more energy\n    #S_dB = librosa.power_to_db(S, ref=np.max)\n    return S_dB ,img\n\ndef scale_minmax(X, min=0.0, max=1.0):\n    X_std = (X - X.min()) / (X.max() - X.min())\n    X_scaled = X_std * (max - min) + min\n    return X_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ni=0\nsr=20000\nfor index,row in meta_train_df.iterrows():\n    if row.label == 'FAKE':\n        if os.path.exists(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER,row.original)):\n              if os.path.exists(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER,index)):\n                    fake_name = index.split('.')[0]+'.wav'\n                    real_name =row.original.split('.')[0]+'.wav'\n                    S_fake,img_fake =create_spectogram(fake_name,sr)\n                    S_real,img_real =create_spectogram(real_name,sr)\n                    if not(np.array_equal(S_fake,S_real)):\n                        diff = np.sum(np.abs(S_real - S_fake))\n                        print(f\"There is a difference in Audio : {diff}\")\n                        plt.figure(figsize=(10, 4))\n                        plt.axis('off')\n                        #librosa.display.specshow(S_fake, x_axis='time',\n                        #          y_axis='mel', sr=sr,\n                        #          fmax=8000)\n                        plt.imshow(img_fake,cmap='gray')\n                        plt.colorbar(format='%+2.0f dB')\n                        plt.title(f'Mel-frequency spectrogram Fake name {fake_name}')\n                        plt.tight_layout()\n                        plt.show()\n                        plt.figure(figsize=(10, 4))\n                        plt.axis('off')\n                        #librosa.display.specshow(S_real, x_axis='time',\n                        #          y_axis='mel', sr=sr,\n                        #          fmax=8000)\n                        plt.imshow(img_real,cmap='gray')\n                        plt.colorbar(format='%+2.0f dB')\n                        plt.title(f'Mel-frequency spectrogram Real name {real_name}')\n                        plt.tight_layout()\n                        plt.show()\n            \n    i=i+1 ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}